{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from neuroHarmonize import harmonizationLearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_dir ='/home/dual4090/lab/github/synth7T-MICCAI/data/original/3T/UCSF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21023600,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning harmonization model from reference data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dual4090/anaconda3/envs/3t7t/lib/python3.11/site-packages/neuroHarmonize/harmonizationLearn.py:336: RuntimeWarning: invalid value encountered in divide\n",
      "  s_data = ((X- stand_mean - mod_mean) / np.dot(np.sqrt(var_pooled), np.ones((1, n_sample))))\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preparation\n",
    "filepaths = [os.path.join(reference_dir, f) for f in os.listdir(reference_dir) if f.endswith('.nii.gz')]\n",
    "if not filepaths:\n",
    "    raise ValueError(\"No NIFTI files found in the reference directory.\")\n",
    "\n",
    "# Create a covariates file. The model needs to know the 'site' name.\n",
    "covars = pd.DataFrame({\n",
    "    'SITE': ['reference_site'] * len(filepaths),\n",
    "})\n",
    "\n",
    "# # 3. Feature Extraction (Brain Masking and Flattening)\n",
    "# print(\"Extracting brain voxels from reference images...\")\n",
    "# masked_data = [nib.load(f).get_fdata().flatten() for f in filepaths]\n",
    "# image_data = np.vstack(masked_data)\n",
    "first_img_data = nib.load(filepaths[0]).get_fdata()\n",
    "brain_voxel_indices = first_img_data != 0\n",
    "\n",
    "# Now, extract the data from all images using these indices\n",
    "image_data_list = []\n",
    "for f in filepaths:\n",
    "    img_data = nib.load(f).get_fdata()\n",
    "    image_data_list.append(img_data[brain_voxel_indices])\n",
    "    \n",
    "image_data = np.vstack(image_data_list)\n",
    "\n",
    "# 4. Learn the Harmonization Model\n",
    "print(\"Learning harmonization model from reference data...\")\n",
    "# The 'image_data_harmonized' is not needed here, we just need the model itself.\n",
    "model, _ = harmonizationLearn(image_data, covars, 'SITE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonization model successfully saved to: /home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/harmonize.pkl\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/harmonize.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "print(f\"Harmonization model successfully saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_path = os.path.join(os.path.dirname(model_path), 'brain_voxel_indices.pkl')\n",
    "with open(indices_path, 'wb') as f:\n",
    "    pickle.dump(brain_voxel_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inference Time Harmonization ---\n",
      "Loading model from /home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/harmonize.pkl...\n",
      "Loading brain voxel indices from /home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/brain_voxel_indices.pkl...\n",
      "Found 6 new scan(s) to harmonize.\n",
      "Resizing scans and extracting brain voxels...\n",
      "Applying harmonization model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dual4090/anaconda3/envs/3t7t/lib/python3.11/site-packages/neuroHarmonize/harmonizationApply.py:141: RuntimeWarning: divide by zero encountered in divide\n",
      "  s_data = ((X- stand_mean - mod_mean) / np.dot(np.sqrt(var_pooled), np.ones((1, n_sample))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing and saving harmonized images...\n"
     ]
    }
   ],
   "source": [
    "# stage2_apply_harmonization_at_inference.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "from neuroHarmonize import harmonizationApply\n",
    "\n",
    "def resize_3d_matrix(input_matrix, target_shape):\n",
    "    original_shape = np.array(input_matrix.shape)\n",
    "    zoom_factors = np.array(target_shape) / original_shape\n",
    "    return zoom(input_matrix, zoom_factors,order=3)\n",
    "\n",
    "def adjust_affine(original_affine, original_shape, new_shape):\n",
    "    \"\"\"\n",
    "    Adjusts the affine matrix for a resized image.\n",
    "    This ensures the image metadata correctly reflects the new voxel sizes.\n",
    "    \"\"\"\n",
    "    original_spacing = np.sqrt(np.sum(original_affine[:3, :3]**2, axis=0))\n",
    "    new_spacing = original_spacing * (np.array(original_shape) / np.array(new_shape))\n",
    "    \n",
    "    new_affine = np.copy(original_affine)\n",
    "    np.fill_diagonal(new_affine, list(new_spacing) + [1])\n",
    "    # To keep orientation, we copy the rotation part of the affine\n",
    "    normalized_original_affine = original_affine[:3, :3] / original_spacing\n",
    "    new_affine[:3, :3] = normalized_original_affine * new_spacing\n",
    "\n",
    "    return new_affine\n",
    "\n",
    "def harmonize_scans_at_inference(new_scans_dir, model_path, indices_path, output_dir):\n",
    "    print(\"--- Inference Time Harmonization ---\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Load the Pre-trained Model and Voxel Indices from Stage 1\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    print(f\"Loading brain voxel indices from {indices_path}...\")\n",
    "    with open(indices_path, 'rb') as f:\n",
    "        brain_voxel_indices = pickle.load(f)\n",
    "    \n",
    "    # Define the target shape for consistency\n",
    "    target_shape = (260, 311, 260)\n",
    "    \n",
    "    # --- MAJOR CHANGE: Verify mask shape once ---\n",
    "    # The mask itself must have the target shape. This is a critical check.\n",
    "    if brain_voxel_indices.shape != target_shape:\n",
    "        raise ValueError(f\"The brain_voxel_indices mask shape {brain_voxel_indices.shape} \"\n",
    "                         f\"does not match the target shape {target_shape}. \"\n",
    "                         \"The model must be trained on resized data.\")\n",
    "\n",
    "    # 2. Prepare New Data\n",
    "    filepaths = [os.path.join(new_scans_dir, f) for f in os.listdir(new_scans_dir) if f.endswith(('.nii.gz', '.nii'))]\n",
    "    if not filepaths:\n",
    "        raise ValueError(\"No NIFTI files found in the new scans directory.\")\n",
    "\n",
    "    print(f\"Found {len(filepaths)} new scan(s) to harmonize.\")\n",
    "\n",
    "    # 3. Resize, then Extract Features\n",
    "    print(\"Resizing scans and extracting brain voxels...\")\n",
    "    image_data_list = []\n",
    "    # Store original nifti objects to get affine later\n",
    "    original_niftis = {}\n",
    "\n",
    "    for f in filepaths:\n",
    "        try:\n",
    "            original_nifti = nib.load(f)\n",
    "            original_niftis[f] = original_nifti\n",
    "            \n",
    "            # --- MAJOR CHANGE: Resize FIRST ---\n",
    "            resized_img_data = resize_3d_matrix(original_nifti.get_fdata(), target_shape)\n",
    "            \n",
    "            # Now the resized image and the mask have the same shape.\n",
    "            # We apply the mask to the RESIZED image.\n",
    "            image_data_list.append(resized_img_data[brain_voxel_indices])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    image_data = np.vstack(image_data_list)\n",
    "    covars = pd.DataFrame({'SITE': ['new_site'] * len(image_data)})\n",
    "\n",
    "    # 4. Apply Harmonization (The \"Inference\" Step)\n",
    "    print(\"Applying harmonization model...\")\n",
    "    # --- FIX: Added batch_col='SITE' argument ---\n",
    "    harmonized_data = harmonizationApply(data=image_data, covars=covars, model=model)\n",
    "\n",
    "    # 5. Reconstruct and Save Harmonized Images at TARGET SHAPE\n",
    "    print(\"Reconstructing and saving harmonized images...\")\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        original_nifti = original_niftis[filepath]\n",
    "        \n",
    "        # --- MAJOR CHANGE: Reconstruct to the TARGET shape, not the original shape ---\n",
    "        # Create a new 3D array filled with zeros with the standard target shape\n",
    "        reconstructed_img_data = np.zeros(target_shape, dtype=np.float32)\n",
    "\n",
    "        # Place the harmonized voxel data back into the correct locations in the new array\n",
    "        reconstructed_img_data[brain_voxel_indices] = harmonized_data[i]\n",
    "        \n",
    "        # --- MAJOR CHANGE: Adjust the affine matrix for the new dimensions ---\n",
    "        new_affine = adjust_affine(original_nifti.affine, original_nifti.shape, target_shape)\n",
    "\n",
    "        # Create a new NIFTI image with the resized data and new affine\n",
    "        harmonized_nifti = nib.Nifti1Image(reconstructed_img_data, affine=new_affine)\n",
    "\n",
    "        base_filename = os.path.basename(filepath)\n",
    "        output_filename = os.path.join(output_dir, f\"harmonized_{base_filename}\")\n",
    "        nib.save(harmonized_nifti, output_filename)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- USER: DEFINE THESE PATHS FOR EACH INFERENCE RUN ---\n",
    "\n",
    "    # Directory containing the new, unharmonized scans you want to process\n",
    "    new_scans_to_harmonize_dir = '/mnt/hdd0/download/sample_GRIP_data/Input/BrainStripped/'\n",
    "\n",
    "    # Path to the model files you created in Stage 1\n",
    "    model_file_path = r'/home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/harmonize.pkl'\n",
    "    indices_file_path = r'/home/dual4090/lab/github/Synthetic_7T_MRI_release/src/dataloader/brain_voxel_indices.pkl'\n",
    "\n",
    "    # Directory where the final, harmonized scans will be saved\n",
    "    output_directory = '/mnt/hdd0/download/sample_GRIP_data/Input/harmonized/'\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    harmonize_scans_at_inference(new_scans_to_harmonize_dir, model_file_path, indices_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3t7t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
