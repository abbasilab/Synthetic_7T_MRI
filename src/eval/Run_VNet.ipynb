{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dual4090/anaconda3/envs/3t7t/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/dual4090/anaconda3/envs/3t7t/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from box import Box\n",
    "import os.path as path\n",
    "\n",
    "import sys, os, json\n",
    "sys.path.append(os.path.join(sys.path[0], '../'))\n",
    "from dataloader.patch_dataloader import patch_dataloader\n",
    "from dataloader.data_utils import load_onefold_dataset, load_all\n",
    "from network.VNet_model import VNetModel\n",
    "from network.WatNet_model import WatNet3DModel, WatNet2DModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(param_dir):\n",
    "    with open(param_dir, 'r') as json_file:\n",
    "        params = json.load(json_file)\n",
    "    return Box(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = '../../config/params_VNet_eval.json'\n",
    "params = load_params(param_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fp': {'subjects': '../../data/subjects.txt', 'filepaths': ['../../data/original'], 'postfixes': ['.nii.gz'], 'eval_modes': ['org', 'down2', 'down4'], 'ckpt_dir': '../../ckpts/tensorlog/VNet_final_ckpts', 'leave_out_subjects': []}, 'data': {'batch_size': 40, 'patch_size': 64, 'patch_overlap': 8}, 'training': {'num_workers': 32, 'max_queue_length': 1000, 'matmul_precision': 'medium', 'precision': '16-mixed'}, 'checkpoint': {'ckpt_dir': '../../ckpts/tensorlog'}}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_params = Box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_params.faa = params.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box({'faa': {'ckpt_dir': '../../ckpts/tensorlog'}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = r'/home/dual4090/lab/github/synth7T-MICCAI/ckpts/tensorlog/VNet_final_ckpts/MAEloss_finalmodel/Synthetic_7T_MRI_VNet_weights.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ckpt_path):\n",
    "    raise ValueError('Checkpoint path does not exist')\n",
    "\n",
    "if not ckpt_path.endswith('.ckpt'):\n",
    "    raise ValueError('Please provide a .ckpt file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path =r'/home/dual4090/lab/github/3T-7T_registration/data/original/3T/01.nii.gz'\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    raise ValueError('Input path does not exist')\n",
    "\n",
    "if os.path.isdir(input_path):\n",
    "    # input is dir, get all .nii.gz files in input dir\n",
    "    input_files = [f for f in os.listdir(input_path) if f.endswith('.nii.gz')]\n",
    "    if not input_files:\n",
    "        raise ValueError('No .nii.gz files found in input directory')\n",
    "    \n",
    "elif os.path.isfile(input_path):\n",
    "    # input is file, check if it is .nii.gz\n",
    "    if not input_path.endswith('.nii.gz'):\n",
    "        raise ValueError('Input file is not a .nii.gz file')\n",
    "    input_files = [input_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dual4090/lab/github/3T-7T_registration/data/original/3T/01.nii.gz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.exists('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_filePaths(file_paths):\n",
    "    # make sure all file paths in list is a nifti file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MRIs(fps_input, fps_mask = None):\n",
    "    \n",
    "    if fps_mask is not None:\n",
    "        flag_mask = True\n",
    "\n",
    "    subjects = []\n",
    "    for i in range(len(fns)):\n",
    "        # normalize value between 0,1\n",
    "        # outlier removal done during preprocessing (5%-95% percentile kept)\n",
    "        rescale1 = tio.RescaleIntensity(out_min_max=(0, 1), percentiles=(0, 100))\n",
    "\n",
    "        subject_dict = {}\n",
    "        if flag3:\n",
    "            subject_dict['t1_3T'] = rescale1(tio.ScalarImage(path.join(fp3, str(fns[i]) + postfix)))\n",
    "        if flag_mask:\n",
    "            subject_dict['mask'] = tio.LabelMap(path.join(fpm, str(fns[i]) + postfix))\n",
    "\n",
    "### what happens if there is no mask?\n",
    "\n",
    "        subject = tio.Subject(id=fns[i], **subject_dict)\n",
    "\n",
    "        subjects.append(subject)\n",
    "    # print('Dataset size:', len(subjects), 'subjects')\n",
    "    return subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_from_paths(filePaths):\n",
    "    #filePaths is a list of file paths\n",
    "    subjects =[]\n",
    "    for i in range(len(filePaths)):\n",
    "        subjects.extend(load_MRIs(filePaths[i]))\n",
    "\n",
    "    tio_dataset = tio.SubjectsDataset(subjects)\n",
    "    print('total number of subjects: ', len(subjects))\n",
    "    return tio_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3t7t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
